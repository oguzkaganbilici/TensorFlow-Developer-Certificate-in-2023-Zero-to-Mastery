{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "- There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables."
      ],
      "metadata": {
        "id": "c2dIRamFITSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import TensorFlow\n"
      ],
      "metadata": {
        "id": "d_2n5SSwJCDY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vl8-GxuwICqo",
        "outputId": "078ebfca-4415-41c3-d173-0794415eb759"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.14.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a data to fit"
      ],
      "metadata": {
        "id": "xhCssMgiJBER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = np.array([-7., -4., -1., 2., 5., 8., 11., 14.])\n",
        "y = np.array([3., 6., 9., 12., 15., 18., 21., 24. ])\n",
        "\n",
        "# Visualize\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, y, color=\"red\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "F73pE9-LIMvK",
        "outputId": "e8da49ad-a188-4546-dd7c-2ad79dda9447"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From graph, it can be seen that, y = X + 10.\n",
        "\n",
        "X -> input features, independent variable\n",
        "y -> output feature, dependent variable"
      ],
      "metadata": {
        "id": "D8JTRPZlJzYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and output shapes\n"
      ],
      "metadata": {
        "id": "0cWSNJbqKcBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-hntZ_8JeaH",
        "outputId": "8ed67afa-b8af-4341-9aa6-d1c9826ad73d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4B3sVtrKKL-",
        "outputId": "db12940e-01ab-4b7f-80d3-05851d21ba1f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turn our Numpy array into tensors"
      ],
      "metadata": {
        "id": "zeTZRnVVHij_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HOrk95hK6Ci",
        "outputId": "46b55dcf-4b80-4a28-d533-a184503afaf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "\n",
        "1.   Creating a model - define the input and output layers, as well as the hidden layers of a deep learning\n",
        "2.   Compiling a model - define  the loss function ( in other words, the function that tells our model how wrong it is) and the optimizer ( tells our model how to improve the patterns its learning) and evalution metrics ( what we can use to interpret the performance of our model)\n",
        "3. Fittin a model - letting the model try to find patterns betwene X & y (features and labels).\n",
        "\n"
      ],
      "metadata": {
        "id": "MIvvMAcfIMdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "\n",
        "# Sequential groups a linear stack of layers into a tf.keras.Model.\n",
        "# Sequential provides training and inference features on this model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1) # we have 1 input and want 1 output. that's why it's 1\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae, # mae => mean absolute error\n",
        "    optimizer=tf.keras.optimizers.SGD(), # SGD => stochastic gradient descent\n",
        "    metrics=[\"mae\"]\n",
        "              )\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kdDyNSdH466",
        "outputId": "a28ca9b3-273d-497f-f681-7a22ae4f2fa7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 7s 7s/step - loss: 14.7785 - mae: 14.7785\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 14.6460 - mae: 14.6460\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 14.5135 - mae: 14.5135\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 14.3810 - mae: 14.3810\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 14.2485 - mae: 14.2485\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ce84ead3790>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X, y\n",
        "\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btxirzTlIG_R",
        "outputId": "628839bb-203f-47a1-e973-cd322517c970"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try and make a prediction using our model"
      ],
      "metadata": {
        "id": "fdhHlKl1NZ0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([17.])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxvRG0HXNX9R",
        "outputId": "ac8065d3-f2a6-4bd7-d474-d93701815b68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 82ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.185071]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Performance of our model is worse than shit. We have to improve it."
      ],
      "metadata": {
        "id": "fkIyMBaNN0ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improve our model\n",
        "\n",
        "we can improve our model, by altering the steps we took to create a model\n",
        "\n",
        "1.   **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2.   **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it traning for longer) or on more data (give the model more examples to learn from)"
      ],
      "metadata": {
        "id": "CRk4tslVE4zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create the model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.SGD(),\n",
        "    metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nylMtQ7rNgRi",
        "outputId": "72ae94d7-5af2-4e4d-dd1c-e1bdefda75ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 13.0505 - mae: 13.0505\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.9180 - mae: 12.9180\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.7855 - mae: 12.7855\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.6530 - mae: 12.6530\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.5205 - mae: 12.5205\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.3880 - mae: 12.3880\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.2555 - mae: 12.2555\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.1230 - mae: 12.1230\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.9905 - mae: 11.9905\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.8580 - mae: 11.8580\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.7255 - mae: 11.7255\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.5930 - mae: 11.5930\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.4605 - mae: 11.4605\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.3280 - mae: 11.3280\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.1955 - mae: 11.1955\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.0630 - mae: 11.0630\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.9305 - mae: 10.9305\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.7980 - mae: 10.7980\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.6655 - mae: 10.6655\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.5330 - mae: 10.5330\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.4005 - mae: 10.4005\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 10.2680 - mae: 10.2680\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.1355 - mae: 10.1355\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.0030 - mae: 10.0030\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.8705 - mae: 9.8705\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.7380 - mae: 9.7380\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6055 - mae: 9.6055\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.4730 - mae: 9.4730\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3405 - mae: 9.3405\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.2080 - mae: 9.2080\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0755 - mae: 9.0755\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9430 - mae: 8.9430\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.8105 - mae: 8.8105\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6780 - mae: 8.6780\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5455 - mae: 8.5455\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4130 - mae: 8.4130\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.2805 - mae: 8.2805\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.1480 - mae: 8.1480\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.0155 - mae: 8.0155\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.8830 - mae: 7.8830\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.7505 - mae: 7.7505\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6180 - mae: 7.6180\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4855 - mae: 7.4855\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.3530 - mae: 7.3530\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2205 - mae: 7.2205\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1063 - mae: 7.1063\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0837 - mae: 7.0837\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8869 - mae: 6.8869\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.8813 - mae: 6.8813\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8756 - mae: 6.8756\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8700 - mae: 6.8700\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8644 - mae: 6.8644\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.8588 - mae: 6.8588\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ce848d2ceb0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try and make a prediction using our new model"
      ],
      "metadata": {
        "id": "15eb95siIOeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([17.])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmZRIiNXHl0E",
        "outputId": "a6f38ed2-e3ab-4d40-a26c-ce46f808a73b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.820974]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ***It's much better than before. Let's continue to improve our model***"
      ],
      "metadata": {
        "id": "1Mg-oDhIIpjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create the model with an extra hidden layer with 100 hidden units\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=None),\n",
        "    tf.keras.layers.Dense(100, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"mae\"]\n",
        "    )\n",
        "\n",
        "# 3. Fit the model\n",
        "\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-aofDusInT4",
        "outputId": "26357fc0-543a-4de9-b201-bcf5994f3516"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 12.8317 - mae: 12.8317\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.9529 - mae: 11.9529\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 11.0418 - mae: 11.0418\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.2020 - mae: 10.2020\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 9.4090 - mae: 9.4090\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8.5680 - mae: 8.5680\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.6757 - mae: 7.6757\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.7270 - mae: 6.7270\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 5.7158 - mae: 5.7158\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.6353 - mae: 4.6353\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.0037 - mae: 4.0037\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.1686 - mae: 4.1686\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.5344 - mae: 4.5344\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.9578 - mae: 4.9578\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.1951 - mae: 5.1951\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.2719 - mae: 5.2719\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.2145 - mae: 5.2145\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.0478 - mae: 5.0478\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.8370 - mae: 4.8370\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.5559 - mae: 4.5559\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.1721 - mae: 4.1721\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.0044 - mae: 4.0044\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.8683 - mae: 3.8683\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.7358 - mae: 3.7358\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.8771 - mae: 3.8771\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.9876 - mae: 3.9876\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.2554 - mae: 4.2554\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.3410 - mae: 4.3410\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.2694 - mae: 4.2694\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.0600 - mae: 4.0600\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.8854 - mae: 3.8854\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.7670 - mae: 3.7670\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6649 - mae: 3.6649\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7224 - mae: 3.7224\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7634 - mae: 3.7634\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7886 - mae: 3.7886\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7992 - mae: 3.7992\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.7963 - mae: 3.7963\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7811 - mae: 3.7811\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.7548 - mae: 3.7548\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.7322 - mae: 3.7322\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.6854 - mae: 3.6854\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.6436 - mae: 3.6436\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.5984 - mae: 3.5984\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.5484 - mae: 3.5484\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4969 - mae: 3.4969\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4712 - mae: 3.4712\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.5010 - mae: 3.5010\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5063 - mae: 3.5063\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.4893 - mae: 3.4893\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.4515 - mae: 3.4515\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3947 - mae: 3.3947\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3803 - mae: 3.3803\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3845 - mae: 3.3845\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3761 - mae: 3.3761\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3589 - mae: 3.3589\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3373 - mae: 3.3373\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3082 - mae: 3.3082\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2694 - mae: 3.2694\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2269 - mae: 3.2269\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.2213 - mae: 3.2213\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1902 - mae: 3.1902\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.1840 - mae: 3.1840\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.1642 - mae: 3.1642\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.1476 - mae: 3.1476\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.1201 - mae: 3.1201\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.0866 - mae: 3.0866\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.0634 - mae: 3.0634\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.0510 - mae: 3.0510\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.0299 - mae: 3.0299\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.9977 - mae: 2.9977\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.9553 - mae: 2.9553\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.9817 - mae: 2.9817\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.9353 - mae: 2.9353\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8854 - mae: 2.8854\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8726 - mae: 2.8726\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8611 - mae: 2.8611\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8364 - mae: 2.8364\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.7995 - mae: 2.7995\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7513 - mae: 2.7513\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6928 - mae: 2.6928\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7094 - mae: 2.7094\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6566 - mae: 2.6566\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6032 - mae: 2.6032\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.5564 - mae: 2.5564\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5329 - mae: 2.5329\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4951 - mae: 2.4951\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4441 - mae: 2.4441\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3806 - mae: 2.3806\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3355 - mae: 2.3355\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2827 - mae: 2.2827\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2572 - mae: 2.2572\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1692 - mae: 2.1692\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1128 - mae: 2.1128\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0568 - mae: 2.0568\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.9896 - mae: 1.9896\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.9195 - mae: 1.9195\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.8622 - mae: 1.8622\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.7683 - mae: 1.7683\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.6872 - mae: 1.6872\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ce7a4769570>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([17.])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GMSgwfxJjam",
        "outputId": "a1f19d67-226a-43d0-cd50-d4ab53ede814"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ce7a479d5a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 80ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.347176]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It is worse than before model. Because our model is overfitted**\n",
        "\n",
        "Common ways to improve a deep model:\n",
        "1.   Adding layers\n",
        "2.   Increase the number of hidden units\n",
        "3.   Change the activation function\n",
        "4.   Change the optimization function\n",
        "5.   Change the learning rate\n",
        "6.   Fitting on more data\n",
        "7. Fitting for longer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BLCXtC-JKPXp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d2eT_CPAYDrv"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}